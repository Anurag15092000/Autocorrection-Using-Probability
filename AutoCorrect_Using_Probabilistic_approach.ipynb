{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "You use autocorrect every day on your cell phone and computer.\n",
        "In this project:\n",
        "- Get a word count given a corpus\n",
        "- Get a word probability in the corpus \n",
        "- Manipulate strings \n",
        "- Filter strings \n",
        "- Implement Minimum edit distance to compare strings and to help find the optimal path for the edits. \n"
      ],
      "metadata": {
        "id": "4ZRsJ-UDEuNT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='0-1'></a>\n",
        "### 0.1 - Edit Distance\n",
        "\n",
        "we will implement models that correct words that are 1 and 2 edit distances away. \n",
        "- We say two words are n edit distance away from each other when we need n edits to change one word into another. \n",
        "\n",
        "An edit could consist of one of the following options: \n",
        "\n",
        "- Delete (remove a letter): ‘hat’ => ‘at, ha, ht’\n",
        "- Switch (swap 2 adjacent letters): ‘eta’ => ‘eat, tea,...’\n",
        "- Replace (change 1 letter to another): ‘jat’ => ‘hat, rat, cat, mat, ...’\n",
        "- Insert (add a letter): ‘te’ => ‘the, ten, ate, ...’\n",
        "\n",
        "You will be using the four methods above to implement an Auto-correct. \n",
        "- To do so, we will  compute probabilities that a certain word is correct given an input. \n",
        "\n",
        "\n",
        "\n",
        "The goal of our spell check model is to compute the following probability:\n",
        "\n",
        "$$P(c|w) = \\frac{P(w|c)\\times P(c)}{P(w)} \\tag{Eqn-1}$$\n",
        "\n",
        " \n",
        "- Equation 1 says that the probability of a word being correct $P(c|w) $is equal to the probability of having a certain word $w$, given that it is correct $P(w|c)$, multiplied by the probability of being correct in general $P(C)$ divided by the probability of that word $w$ appearing $P(w)$ in general.\n",
        "- To compute equation 1, you will first import a data set and then create all the probabilities that you need using that data set. "
      ],
      "metadata": {
        "id": "iLRaQMnIFQzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='1'></a>\n",
        "## 1 - Data Preprocessing "
      ],
      "metadata": {
        "id": "ZAWTuQ2jF13N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "ykxsrU2CFFs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='ex-1'></a>\n",
        "###  a - process_data\n",
        "Implement the function `process_data` which \n",
        "\n",
        "1) Reads in a corpus (text file)\n",
        "\n",
        "2) Changes everything to lowercase\n",
        "\n",
        "3) Returns a list of words. "
      ],
      "metadata": {
        "id": "yEVhemSmGlVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(file_name):\n",
        "    \n",
        "    words = [] \n",
        "   \n",
        "    with open(file_name) as fh:\n",
        "        data=fh.read()\n",
        "\n",
        "    \n",
        "\n",
        "    data=data.lower()\n",
        "    #Convert every word to lower case and return them in a list.\n",
        "    words=re.findall(r'\\w+', data)\n",
        "    # we split the data into a list words while removing the new line character\n",
        "\n",
        "    \n",
        "    return words"
      ],
      "metadata": {
        "id": "XOLd9vVWGq1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_l = process_data('shakespeare.txt')\n",
        "vocab = set(word_l)  # this will be your new vocabulary\n",
        "print(f\"The first ten words in the text are: \\n{word_l[0:10]}\")\n",
        "print(f\"There are {len(vocab)} unique words in the vocabulary.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG89oeg4HX91",
        "outputId": "e8810731-bdd7-438b-a732-5ff6d0e8ee5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first ten words in the text are: \n",
            "['this', 'is', 'the', '100th', 'etext', 'file', 'presented', 'by', 'project', 'gutenberg']\n",
            "There are 23902 unique words in the vocabulary.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='ex-2'></a>\n",
        "###  b - get_count\n",
        "\n",
        "Implement a `get_count` function that returns a dictionary\n",
        "- The dictionary's keys are words\n",
        "- The value for each word is the number of times that word appears in the corpus."
      ],
      "metadata": {
        "id": "wuNcMqy2IjRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_count(word_l):\n",
        "    \n",
        "    word_count_dict = {} \n",
        "\n",
        "    word_count_dict=Counter(word_l)\n",
        "    # counter for every unique word in the text document\n",
        "    return word_count_dict"
      ],
      "metadata": {
        "id": "6YBBUNhiIn_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_count_dict = get_count(word_l)\n",
        "print(f\"There are {len(word_count_dict)} key values pairs\")\n",
        "print(f\"The count for the word 'thee' is {word_count_dict.get('thee',0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKuZDucYJAxJ",
        "outputId": "59a78b92-3230-4362-e138-2073a1820e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 23902 key values pairs\n",
            "The count for the word 'thee' is 3181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='ex-3'></a>\n",
        "### c - get_probs\n",
        "Given the dictionary of word counts, compute the probability that each word will appear if randomly selected from the corpus of words.\n",
        "\n",
        "$$P(w_i) = \\frac{C(w_i)}{M} \\tag{Eqn-2}$$\n",
        "where \n",
        "\n",
        "$C(w_i)$ is the total number of times $w_i$ appears in the corpus.\n",
        "\n",
        "$M$ is the total number of words in the corpus.\n",
        "\n"
      ],
      "metadata": {
        "id": "cargaMvZJMlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_probs(word_count_dict):\n",
        "    \n",
        "    probs = {} \n",
        "    \n",
        "    m=sum(word_count_dict.values())\n",
        "    for word in word_count_dict:\n",
        "        probs[word]=word_count_dict.get(word)/m\n",
        "    # probability of each word occuring in the text document\n",
        "    return probs"
      ],
      "metadata": {
        "id": "hF3rZimWJDXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = get_probs(word_count_dict)\n",
        "print(f\"Length of probs is {len(probs)}\")\n",
        "print(f\"P('thee') is {probs['thee']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5S01GZz9JnIf",
        "outputId": "38b3a4f8-58a2-49ef-91e6-e13975237963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of probs is 23902\n",
            "P('thee') is 0.0034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='2'></a>\n",
        "## 2 - String Manipulations\n",
        "\n",
        "Now that you have computed $P(w_i)$ for all the words in the corpus,we  gave writtn e a few functions to manipulate strings so that we can edit the erroneous strings and return the right spellings of the words.WE will use functions:\n",
        "* `delete_letter`: given a word, it returns all the possible strings that have **one character removed**. \n",
        "* `switch_letter`: given a word, it returns all the possible strings that have **two adjacent letters switched**.\n",
        "* `replace_letter`: given a word, it returns all the possible strings that have **one character replaced by another different letter**.\n",
        "* `insert_letter`: given a word, it returns all the possible strings that have an **additional character inserted**. \n"
      ],
      "metadata": {
        "id": "wxQW5stGJsxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='ex-4'></a>\n",
        "###  a - delete_letter\n",
        "\n",
        " given a word it returns a list of strings with one character deleted. \n",
        "\n",
        "For example, given the word **nice**, it would return the set: {'ice', 'nce', 'nic', 'nie'}. "
      ],
      "metadata": {
        "id": "Ee2RO4vNKYGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_letter(word, verbose=False):\n",
        "    \n",
        "    \n",
        "    delete_l = []\n",
        "    split_l = []\n",
        "    \n",
        "  \n",
        "    split_l=[(word[:i],word[i:]) for i in range(len(word)+1)]\n",
        "    delete_l=[L+R[1:] for L,R in split_l if R]\n",
        " \n",
        "    if verbose: print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
        "\n",
        "    return  delete_l"
      ],
      "metadata": {
        "id": "2B67StElJsY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_word_l = delete_letter(word=\"bend\",\n",
        "                        verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOmbwSvSK55P",
        "outputId": "8a042bb7-4fe2-4732-ad4e-f7ee1944ce51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input word bend, \n",
            "split_l = [('', 'bend'), ('b', 'end'), ('be', 'nd'), ('ben', 'd'), ('bend', '')], \n",
            "delete_l = ['end', 'bnd', 'bed', 'ben']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='ex-5'></a>\n",
        "### b - switch_letter\n",
        "\n",
        " It takes in a word and returns a list of all the possible switches of two letters that are adjacent to each other\n",
        "- For example, given the word 'eta', it returns {'eat', 'tea'}, but does not return 'ate'."
      ],
      "metadata": {
        "id": "5VVbCYdjLC5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def switch_letter(word, verbose=False):\n",
        "    \n",
        "    \n",
        "    switch_l = []\n",
        "    split_l = []\n",
        "    \n",
        "\n",
        "    split_l=[(word[:i],word[i:]) for i in range(len(word)+1)]\n",
        "  \n",
        "    for i in range(0,len(word)-1):\n",
        "        s=word[:i]+word[i+1]+word[i]+word[i+2:]\n",
        "        switch_l.append(s)\n",
        "\n",
        "    \n",
        "    \n",
        "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\") \n",
        "    \n",
        "    return switch_l"
      ],
      "metadata": {
        "id": "VHa2KgIRLdy7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "switch_word_l = switch_letter(word=\"eta\",\n",
        "                         verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n-SrNvhL1DP",
        "outputId": "b68203ec-bb3a-4d11-9ceb-bbc8339b1d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word = eta \n",
            "split_l = [('', 'eta'), ('e', 'ta'), ('et', 'a'), ('eta', '')] \n",
            "switch_l = ['tea', 'eat']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='ex-6'></a>\n",
        "### c - replace_letter\n",
        " we implement a function that takes in a word and returns a list of strings with one **replaced letter** from the original word. \n"
      ],
      "metadata": {
        "id": "L2Y1FMx9L8OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_letter(word, verbose=False):\n",
        "   \n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    \n",
        "   \n",
        "    split_l = []\n",
        "\n",
        "\n",
        "    split_l=[(word[:i],word[i:]) for i in range(len(word))]\n",
        "    replace_set=[L+C+R[1:] for L,R in split_l if R for C in letters]\n",
        "\n",
        "    replace_l = sorted(list(replace_set))\n",
        "    replace_l= [i for i in replace_l if i != word]\n",
        "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")   \n",
        "    \n",
        "    return replace_l"
      ],
      "metadata": {
        "id": "KIWl3328MTz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_l = replace_letter(word='can',\n",
        "                              verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWuD5W3qM0qN",
        "outputId": "bcec7cc8-f70f-4e57-f82f-c17db7fa8472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word = can \n",
            "split_l = [('', 'can'), ('c', 'an'), ('ca', 'n')] \n",
            "replace_l ['aan', 'ban', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cbn', 'ccn', 'cdn', 'cen', 'cfn', 'cgn', 'chn', 'cin', 'cjn', 'ckn', 'cln', 'cmn', 'cnn', 'con', 'cpn', 'cqn', 'crn', 'csn', 'ctn', 'cun', 'cvn', 'cwn', 'cxn', 'cyn', 'czn', 'dan', 'ean', 'fan', 'gan', 'han', 'ian', 'jan', 'kan', 'lan', 'man', 'nan', 'oan', 'pan', 'qan', 'ran', 'san', 'tan', 'uan', 'van', 'wan', 'xan', 'yan', 'zan']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='ex-7'></a>\n",
        "### d- insert_letter\n",
        "\n",
        " Now we implement a function that takes in a word and returns a list with a letter inserted at every offset.\n"
      ],
      "metadata": {
        "id": "C_kNg9HrM9Ue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_letter(word, verbose=False):\n",
        "   \n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    insert_l = []\n",
        "    split_l = []\n",
        "    \n",
        "\n",
        "    split_l=[(word[:i],word[i:]) for i in range(len(word)+1)]\n",
        "    insert_l=[L+C+R for L,R in split_l  for C in letters]\n",
        "        \n",
        "\n",
        "    \n",
        "    if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
        "    \n",
        "    return insert_l"
      ],
      "metadata": {
        "id": "Cf4b4os-NFkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insert_l = insert_letter('at', True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbENlYpeNQtN",
        "outputId": "87a7e6ed-fd13-4804-b856-5921253f5a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word at \n",
            "split_l = [('', 'at'), ('a', 't'), ('at', '')] \n",
            "insert_l = ['aat', 'bat', 'cat', 'dat', 'eat', 'fat', 'gat', 'hat', 'iat', 'jat', 'kat', 'lat', 'mat', 'nat', 'oat', 'pat', 'qat', 'rat', 'sat', 'tat', 'uat', 'vat', 'wat', 'xat', 'yat', 'zat', 'aat', 'abt', 'act', 'adt', 'aet', 'aft', 'agt', 'aht', 'ait', 'ajt', 'akt', 'alt', 'amt', 'ant', 'aot', 'apt', 'aqt', 'art', 'ast', 'att', 'aut', 'avt', 'awt', 'axt', 'ayt', 'azt', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='3'></a>\n",
        "## 3 - Edit one letter\n",
        "\n",
        "Now that we  have implemented the string manipulations, we will create two functions that, given a string, will return all the possible single and double edits on that string. These will be `edit_one_letter()` and `edit_two_letters()`."
      ],
      "metadata": {
        "id": "LSLy4ZsqNcIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_one_letter(word, allow_switches = True):\n",
        "    \n",
        "    \n",
        "    edit_one_set = set()\n",
        "    \n",
        "\n",
        "    edit_one_set.update(delete_letter(word))\n",
        "    edit_one_set.update(switch_letter(word))\n",
        "    edit_one_set.update(insert_letter(word))\n",
        "    edit_one_set.update(replace_letter(word))\n",
        "\n",
        "    return set(edit_one_set)"
      ],
      "metadata": {
        "id": "qqHUsseANovu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_word = \"at\"\n",
        "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
        "\n",
        "tmp_edit_one_l = sorted(list(tmp_edit_one_set))\n",
        "\n",
        "print(f\"input word {tmp_word} \\nedit_one_l \\n{tmp_edit_one_l}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh5ctCmAN-TD",
        "outputId": "b30500f9-f197-4086-e383-f220029f6688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input word at \n",
            "edit_one_l \n",
            "['a', 'aa', 'aat', 'ab', 'abt', 'ac', 'act', 'ad', 'adt', 'ae', 'aet', 'af', 'aft', 'ag', 'agt', 'ah', 'aht', 'ai', 'ait', 'aj', 'ajt', 'ak', 'akt', 'al', 'alt', 'am', 'amt', 'an', 'ant', 'ao', 'aot', 'ap', 'apt', 'aq', 'aqt', 'ar', 'art', 'as', 'ast', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aut', 'av', 'avt', 'aw', 'awt', 'ax', 'axt', 'ay', 'ayt', 'az', 'azt', 'bat', 'bt', 'cat', 'ct', 'dat', 'dt', 'eat', 'et', 'fat', 'ft', 'gat', 'gt', 'hat', 'ht', 'iat', 'it', 'jat', 'jt', 'kat', 'kt', 'lat', 'lt', 'mat', 'mt', 'nat', 'nt', 'oat', 'ot', 'pat', 'pt', 'qat', 'qt', 'rat', 'rt', 'sat', 'st', 't', 'ta', 'tat', 'tt', 'uat', 'ut', 'vat', 'vt', 'wat', 'wt', 'xat', 'xt', 'yat', 'yt', 'zat', 'zt']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='3-2'></a>\n",
        "### a - Edit Two Letters\n",
        "\n",
        "<a name='ex-9'></a>\n",
        "### Exercise 9 - edit_two_letters\n",
        "\n",
        "wegeneralize this to implement to get two edits on a word. To do so, we would have to get all the possible edits on a single word and then for each modified word, we would have to modify it again. "
      ],
      "metadata": {
        "id": "yjwU7tqxO8V9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_two_letters(word, allow_switches = True):\n",
        "   \n",
        "    \n",
        "    edit_two_set = set()\n",
        "    \n",
        "\n",
        "    edit_one_set=set()\n",
        "    edit_one_set.update(delete_letter(word))\n",
        "    edit_one_set.update(switch_letter(word))\n",
        "    edit_one_set.update(insert_letter(word))\n",
        "    edit_one_set.update(replace_letter(word))\n",
        "    \n",
        "\n",
        "    L=list(edit_one_set)\n",
        "    for i in L:\n",
        "        edit_two_set.update(insert_letter(i))\n",
        "        edit_two_set.update(replace_letter(i))\n",
        "        edit_two_set.update(switch_letter(i))\n",
        "        edit_two_set.update(delete_letter(i))\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "    return set(edit_two_set)"
      ],
      "metadata": {
        "id": "z5eBg4JcO7eC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_edit_two_set = edit_two_letters(\"a\")\n",
        "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
        "print(f\"Number of strings with edit distance of two: {len(tmp_edit_two_l)}\")\n",
        "print(f\"First 10 strings {tmp_edit_two_l[:10]}\")\n",
        "print(f\"Last 10 strings {tmp_edit_two_l[-10:]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usbcpfyJn4Hq",
        "outputId": "10d0e97b-9f62-4a78-8944-54c44d847dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of strings with edit distance of two: 2654\n",
            "First 10 strings ['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag']\n",
            "Last 10 strings ['zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='4'></a>\n",
        "### 4 - Suggest Spelling Suggestions\n",
        "\n",
        "Now you will use your `edit_two_letters` function to get a set of all the possible 2 edits on your word. You will then use those strings to get the most probable word you meant to type a.k.a your typing suggestion."
      ],
      "metadata": {
        "id": "55tiXLaZtCS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_corrections(word, probs, vocab, n=4, verbose = False):\n",
        "    \n",
        "    suggestions = []\n",
        "    n_best = []\n",
        "    \n",
        "    ### START CODE HERE ###\n",
        "    #Step 1: create suggestions as described above  \n",
        "    one_edit=list(edit_one_letter(word))\n",
        "    two_edit=list(edit_two_letters(word))\n",
        "    list1=set()\n",
        "    for i in vocab:\n",
        "        if(i ==word):\n",
        "            list1.add(i)\n",
        "            break\n",
        "    list2=set()\n",
        "    for i in one_edit:\n",
        "        if i in vocab:\n",
        "            list2.add(i)\n",
        "    list3=set()\n",
        "    for i in two_edit:\n",
        "        if i in vocab:\n",
        "            list3.add(i)\n",
        "    suggestions=list1 or list2 or list3\n",
        "    best_words={}\n",
        "    for i in list(suggestions):\n",
        "        if i in probs:\n",
        "            best_words[i]=probs.get(i)\n",
        "        else:\n",
        "            best_words[i]=0\n",
        "    \n",
        "    keys = list(best_words.keys())\n",
        "    values = list(best_words.values())\n",
        "    sorted_value_index = np.argsort(values)[::-1]\n",
        "    sorted_dict = {keys[i]: values[i] for i in sorted_value_index}\n",
        "    if (n>len(sorted_dict)):\n",
        "        for i in sorted_dict:\n",
        "            n_best.append((i,sorted_dict.get(i)))\n",
        "    else:\n",
        "        \n",
        "        d1= dict(list(sorted_dict.items())[0:n])\n",
        "        for i in d1:\n",
        "            n_best.append((i,d1.get(i)))\n",
        "  \n",
        "    \n",
        "\n",
        "    \n",
        "    if verbose: print(\"entered word = \", word, \"\\nsuggestions = \", suggestions)\n",
        "\n",
        "    return n_best"
      ],
      "metadata": {
        "id": "NBbgp4_isge-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_word = 'dys' \n",
        "tmp_corrections = get_corrections(my_word, probs, vocab, 2, verbose=True) \n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n",
        "\n",
        "print(f\"data type of corrections {type(tmp_corrections)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XW0pxAy0tuYr",
        "outputId": "44bb1e00-bf70-45bd-80b1-5e1aaf85302e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entered word =  dys \n",
            "suggestions =  {'dye', 'dy', 'dis', 'des', 'days'}\n",
            "word 0: days, probability 0.000225\n",
            "word 1: dis, probability 0.000005\n",
            "data type of corrections <class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a name='4'></a>\n",
        "## 4a - Minimum Edit Distance\n",
        "\n",
        "Now that we have implemented our auto-correct, we need to  evaluate the similarity between two strings. For example: 'waht' and 'what'\n",
        "\n"
      ],
      "metadata": {
        "id": "3_tc6UKEu1oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def min_edit_distance(source, target, ins_cost = 1, del_cost = 1, rep_cost = 2):\n",
        "   \n",
        "    m = len(source) \n",
        "    n = len(target) \n",
        "    #initialize cost matrix with zeros and dimensions (m+1,n+1) \n",
        "    D = np.zeros((m+1, n+1), dtype=int) \n",
        "    \n",
        "\n",
        "    \n",
        "    # Fill in column 0, from row 1 to row m, both inclusive\n",
        "    for row in range(1,m+1): \n",
        "        D[row,0] = D[row-1,0]+del_cost\n",
        "        \n",
        "    # Fill in row 0, for all columns from 1 to n, both inclusive\n",
        "    for col in range(1,n+1):\n",
        "        D[0,col] = D[0,col-1]+ins_cost\n",
        "        \n",
        "    # Loop through row 1 to row m, both inclusive\n",
        "    for row in range(1,m+1):\n",
        "        \n",
        "        # Loop through column 1 to column n, both inclusive\n",
        "        for col in range(1,n+1):\n",
        "            \n",
        "            # Intialize r_cost to the 'replace' cost that is passed into this function\n",
        "            r_cost = rep_cost\n",
        "            \n",
        "            # Check to see if source character at the previous row\n",
        "            # matches the target character at the previous column, \n",
        "            if (source[row-1]==target[col-1]): \n",
        "                # Update the replacement cost to 0 if source and target are the same\n",
        "                r_cost = 0\n",
        "                \n",
        "            # Update the cost at row, col based on previous entries in the cost matrix\n",
        "\n",
        "            D[row,col] = min(D[row-1,col]+del_cost,D[row,col-1]+ins_cost,D[row-1,col-1]+r_cost)\n",
        "            \n",
        "    # Set the minimum edit distance with the cost found at row m, column n \n",
        "    med = D[m,n]\n",
        "    \n",
        "\n",
        "    return D, med"
      ],
      "metadata": {
        "id": "mZsHE2aTuoe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source =  'play'\n",
        "target = 'stay'\n",
        "matrix, min_edits = min_edit_distance(source, target)\n",
        "print(\"minimum edits: \",min_edits, \"\\n\")\n",
        "idx = list('#' + source)\n",
        "cols = list('#' + target)\n",
        "df = pd.DataFrame(matrix, index=idx, columns= cols)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "6FBLaEurviJS",
        "outputId": "ebae5c6f-04fd-4695-a33e-2bba51a83b80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "minimum edits:  4 \n",
            "\n",
            "   #  s  t  a  y\n",
            "#  0  1  2  3  4\n",
            "p  1  2  3  4  5\n",
            "l  2  3  4  5  6\n",
            "a  3  4  5  4  5\n",
            "y  4  5  6  5  4\n"
          ]
        }
      ]
    }
  ]
}